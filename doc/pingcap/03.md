# buffer pools

- locks and latches
  
buffer pool

- page table
- dirty-flag
- pin counter
- Optimizations
  - Multiple Buffer Pools
  - Pre-Fetching
  - Scan Sharing
- Allocation Policies
  - Global Policies
  - Local Policies

Replacement Policies

- Least Recently Used (LRU)
- CLOCK, 二次机会算法
- LRU-K: Take into account history of the last K references

LRU LRU(1)

# 缓存淘汰机制

缓存淘汰机制在缓存需要被清理的时候使用。主要有以下几种算法

- FIFO：先入先出，优先清理最先被缓存的数据对象。实现简单，直接使用队列就可以实现。
- LRU：最近最久未被使用，优先清理最近没有被使用的对象。使用一个最近使用时间降序的有序队列，优先清理队列对后的数据。
  与LFU的区别在于：    LRU是按照最近使用使用的时间排序，LFU需要维护一个使用频次并用于排序。
- LFU：最近最少使用，优先清理最近最少使用的数据对象。使用一个使用次数降序的有序队列，优先清理队列最后的数据。
  
// 其中LRU和LFU可以通过维护一个Hashmap来提高访问效率。

## LRU-K 

LRU-K的主要目的是为了解决LRU算法`“缓存污染”`的问题，

其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。也就是说没有到达K次访问的数据并不会被缓存，
这也意味着需要对于缓存数据的访问次数进行计数，并且访问记录不能无限记录，也需要使用替换算法进行替换。
当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。

简单说：

当访问次数达到K次后，将数据索引从历史队列移到缓存队列中（缓存队列时间降序）；
缓存数据队列中被访问后重新排序；需要淘汰数据时，淘汰缓存队列中排在末尾的数据。

## Q1. LRU缓存污染指的是什么情况？

偶发性的、周期性的批量操作会导致LRU命中率急剧下降，这时候缓存中的数据大部分都不是热点数据。

## Q2. LRU-K的K值怎么确定？

K值增大，命中率会更高，但是适应性差（清除一个缓存需要大量的数据访问，一般选择LRU-2）。

```text
LRUCache(int capacity) 以正整数作为容量 capacity 初始化 LRU 缓存
int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1, 有就获取，同时将该key放到最前面
void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。存放的时候，都是放在最前面的
函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。
```

LRU(2)
